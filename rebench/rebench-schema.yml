name: ReBench Configuration
desc: Specifies the elements of the YAML-based configuration format.

schema;runs_type:
  type: map
  mapping: &EXP_RUN_DETAILS
    invocations:
      type: int
      # default: 1  #  can't specify this here, because the defaults override settings
      desc: |
        The number of times a virtual machine is executed to run one experiment.
        Thus, this is the number of runs per virtual machine.
    iterations:
      type: int
      # default: 1 #  can't specify this here, because the defaults override settings
      desc: |
        The number of times a benchmark is executed within a virtual machine
        invocation. This needs to be supported by a benchmark harness and
        ReBench passes this value on to the harness or benchmark.
    warmup:
      type: int
      desc: |
        Consider the first N iterations as warmup.
        This is used by reporters, for instance to discard these
        N measurements before calculating statistics.

    min_iteration_time:
      type: int
      # TODO: make sure this is the correct default value
      # default: 50 #  can't specify this here, because the defaults override settings
      desc: |
        Give a warning if the average run time is below this value in
        milliseconds.
    max_invocation_time:
      type: int
      desc: |
        Time in second after which an invocation is terminated.
        The value -1 indicates that there is no timeout intended.
      # default: -1 #  can't specify this here, because the defaults override settings
    parallel_interference_factor:
      type: float
      desc: |
        A higher factor means a lower degree of parallelism.
        TODO: should probably be removed
        TODO: then again, we might want this for research on the impact
    execute_exclusively:
      type: bool
      # default: false #  can't specify this here, because the defaults override settings
      desc: |
        TODO: probably needs to be removed, not sure. parallel exec of
        benchmarks introduced a lot of noise

schema;reporting_type:
  type: map
  mapping:
    codespeed:
      type: map
      desc: Send results to Codespeed for continuous performance tracking.
      mapping:
        project:
          type: str
          desc: The Codespeed project corresponding to the results.
        url:
          type: str
          desc: |
            The URL to the /result/add/json/ rest endpoint for submitting
            results (the full URL).

schema;variables:
  desc: |
    defining variables for an experiment. not, this is not a type used by the
    schema. instead, we use YAML to reuse this definition
  type: map
  mapping: &EXP_VARIABLES
    input_sizes:
      type: seq
      desc: |
        Many benchmark harnesses and benchmarks take an input size as a
        configuration parameter. It might identify a data file, or some other
        way to adjust the amount of computation performed.
      # default: ['']  # that's the semantics, but pykwalify does not support it
      sequence:
        - type: scalar
    cores:
      type: seq
      desc: The cores to be used by the benchmark.
      # default: [1]  # that's the semantics, but pykwalify does not support it
      sequence:
        - type: scalar
    variable_values:
      type: seq
      desc: Another dimension by which the benchmark execution can be varied.
      # default: ['']  # that's the semantics, but pykwalify does not support it
      sequence:
        - type: scalar

schema;benchmark_type_str:
  type: str
  desc: The name of a benchmark, can be simply the name.
schema;benchmark_type_map:
  type: map
  desc: |
    The name of a benchmark and additional information.
  matching-rule: 'any'
  mapping:
    regex;(.+):
      type: map
      mapping:
        <<: *EXP_RUN_DETAILS
        <<: *EXP_VARIABLES
        extra_args:
          type: scalar
          desc: This extra argument is appended to the benchmark's command line.
          # default: '' # causes issue in pykwalify
        command:
          type: str
          desc: use this command instead of the name for the command line.
        codespeed_name:
          type: str
          desc: |
            A name used for this benchmark when sending data to Codespeed.
            This is useful to have a name different from the one relevant
            at the suite level.

schema;benchmark_suite_type:
  type: map
  mapping:
    <<: *EXP_RUN_DETAILS
    <<: *EXP_VARIABLES
    gauge_adapter:
      type: str
      required: yes
      desc: |
        Name of the parser that interpreters the output of the benchmark harness
    command:
      type: str
      required: yes
      desc: |
        The command for the benchmark harness. It's going to be combined with the
        VM's command line. It supports various format variables, including:
         - benchmark (the benchmark's name)
         - input (the input variable's value)
         - variable (another variable's value)
         - cores (the number of cores to be used by the benchmark)
    location:
      type: str
      desc: |
        The path to the benchmark harness. Execution use this location as
        working directory. It overrides the location/path of a VM.
    build:
      desc: |
        The given string is executed by the system's shell and can be used to
        build a benchmark suite. It is executed once before any benchmarks are
        executed. If `location` is set, it is used as working directory.
        Otherwise, it is the current working directory of ReBench.
      type: str
    benchmarks:
      type: seq
      required: yes
      matching: any
      sequence:
        - include: benchmark_type_str
        - include: benchmark_type_map
    description:
      type: str
      desc: A description of the benchmark.
    desc:
      type: str
      desc: A description of the benchmark.

schema;vm_type:
  type: map
  mapping:
    <<: *EXP_RUN_DETAILS
    <<: *EXP_VARIABLES
    path:
      type: str
      required: no
      desc: |
        Path to the binary.
        If not given, it's up to the shell to find the binary
    binary:
      type: str
      required: yes
      desc: the name of the binary to be used
    args:
      type: str
      # default: '' # causes issue in pykwalify
      desc: |
        The arguments when assembling the command line.
        TODO: do we support format string parameters here?
              if so, which?
    desc:
      type: str
    description:
      type: str
    build:
      desc: |
        The given string is executed by the system's shell and can be used to
        build a VM. It is executed once before any benchmarks are executed with
        the VM. If `path` is set, it is used as working directory. Otherwise,
        it is the current working directory of ReBench.
      type: str

schema;exp_suite_type:
  desc: A list of suites
  type: seq
  sequence:
    - type: str

schema;exp_exec_type:
  desc: A VM and a set of benchmarks
  type: map
  mapping:
    regex;(.+):
      type: map
      mapping:
        <<: *EXP_RUN_DETAILS
        <<: *EXP_VARIABLES
        suites:
          include: exp_suite_type

schema;experiment_type:
  desc: Defined an experiment for a specific VM
  type: map
  mapping:
    <<: *EXP_RUN_DETAILS
    <<: *EXP_VARIABLES
    description:
      type: str
      desc: Description of the experiment
    desc:
      type: str
      desc: Description of the experiment
    data_file:
      desc: The data for this experiment goes into a separate file
      type: str
    reporting:
      include: reporting_type

    executions:
      type: seq
      desc: |
        The VMs used for execution, possibly with specific suites assigned
      sequence:
        - type: str
        - include: exp_exec_type
    suites:
      desc: List of benchmark suites to be used.
      include: exp_suite_type

type: map
mapping:
  regex;(\..+):
    type: any
    desc: dot properties, for example `.test` are going to be ignored
  standard_experiment:
    type:     str
    default:  all
  standard_data_file:
    type:     str
    default:  rebench.data
  build_log:
    type:     str
    default:  build.log
  runs:
    include: runs_type
  reporting:
    include: reporting_type
  benchmark_suites:
    type: map
    mapping:
      regex;(.+):
        include: benchmark_suite_type
  virtual_machines:
    type: map
    mapping:
      regex;(.+):
        include: vm_type
  experiments:
    type: map
    mapping:
      regex;(.+):
        include: experiment_type
